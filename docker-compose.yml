version: "3.8"

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: receipt-intelligence
    restart: unless-stopped
    ports:
      - "${STREAMLIT_SERVER_PORT:-8501}:8501"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - PINECONE_INDEX_NAME=${PINECONE_INDEX_NAME:-receipt-index}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-text-embedding-3-small}
      - RECEIPT_DATA_PATH=/app/data/receipt_samples_100
      - STREAMLIT_SERVER_PORT=8501
      - STREAMLIT_SERVER_HEADLESS=true
      - STREAMLIT_SERVER_ENABLE_CORS=false
      - PYTHONUNBUFFERED=1
    volumes:
      - receipt_data:/app/data
      - ./src:/app/src:ro  # Mount source for development (read-only)
    networks:
      - receipt_network
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8501')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Optional: Indexer service for one-time data ingestion
  indexer:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: receipt-indexer
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - PINECONE_INDEX_NAME=${PINECONE_INDEX_NAME:-receipt-index}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-text-embedding-3-small}
      - RECEIPT_DATA_PATH=/app/data/receipt_samples_100
      - PYTHONUNBUFFERED=1
    volumes:
      - receipt_data:/app/data
    command: >
      python -c "
      import sys
      sys.path.insert(0, '.')
      from src.vectorstore.vector_manager import VectorManager
      from src.parsers.receipt_parser import ReceiptParser
      from src.chunking.receipt_chunker import ReceiptChunker
      from src.utils.data_loader import load_receipt_files
      import os

      print('Initializing components...')
      vector_manager = VectorManager()
      parser = ReceiptParser()
      chunker = ReceiptChunker()

      # Check if index has data
      stats = vector_manager.get_index_stats()
      if stats.get('total_vector_count', 0) > 0:
        print(f'Index already contains {stats[\"total_vector_count\"]} vectors. Skipping indexing.')
        sys.exit(0)

      print('Loading receipt data...')
      data_path = os.getenv('RECEIPT_DATA_PATH', '/app/data/receipt_samples_100')
      receipts = load_receipt_files(data_path)
      print(f'Loaded {len(receipts)} receipt files')

      print('Parsing and chunking receipts...')
      all_chunks = []
      for receipt_data in receipts:
        try:
          receipt = parser.parse(receipt_data['content'], receipt_data['filename'])
          chunks = chunker.chunk_receipt(receipt)
          all_chunks.extend(chunks)
        except Exception as e:
          print(f'Error processing {receipt_data[\"filename\"]}: {e}')
          continue

      print(f'Created {len(all_chunks)} chunks from {len(receipts)} receipts')

      if all_chunks:
        print('Indexing chunks...')
        indexed = vector_manager.index_chunks(all_chunks, batch_size=50)
        print(f'Successfully indexed {indexed} chunks')
      else:
        print('No chunks to index')
      "
    depends_on: []
    profiles:
      - indexer
    networks:
      - receipt_network

volumes:
  receipt_data:
    driver: local

networks:
  receipt_network:
    driver: bridge
